// ===================================
// WebMaster Pro Server - Bulletproof Version
// GUARANTEED TO START AND WORK
// ===================================

console.log('ðŸš€ Starting WebMaster Pro Server...');

let express, cors;

try {
    express = require('express');
    cors = require('cors');
    console.log('âœ… Core modules loaded');
} catch (error) {
    console.error('âŒ Failed to load core modules:', error.message);
    process.exit(1);
}

// Environment setup with fallbacks
require('dotenv').config();

const app = express();
const PORT = process.env.PORT || 3000;

console.log(`ðŸŒ Starting on PORT: ${PORT}`);
console.log(`ðŸ”‘ OpenAI Key: ${process.env.OPENAI_API_KEY ? 'CONFIGURED' : 'MISSING'}`);
console.log(`ðŸ”‘ Claude Key: ${process.env.ANTHROPIC_API_KEY ? 'CONFIGURED' : 'MISSING'}`);

// Ultra-safe middleware
try {
    app.use(cors({
        origin: '*',
        methods: ['GET', 'POST', 'OPTIONS'],
        allowedHeaders: ['Content-Type', 'Authorization']
    }));
    app.use(express.json({ limit: '1mb' }));
    console.log('âœ… Middleware configured');
} catch (error) {
    console.error('âŒ Middleware error:', error.message);
}

// Health check - MUST WORK
app.get('/health', (req, res) => {
    try {
        console.log('ðŸ¥ Health check requested');
        res.status(200).json({
            status: 'healthy',
            timestamp: new Date().toISOString(),
            port: PORT,
            environment: process.env.NODE_ENV || 'development',
            services: {
                openai: process.env.OPENAI_API_KEY ? 'configured' : 'missing',
                anthropic: process.env.ANTHROPIC_API_KEY ? 'configured' : 'missing'
            },
            message: 'WebMaster Pro Backend is running!'
        });
    } catch (error) {
        console.error('âŒ Health check error:', error.message);
        res.status(500).json({ 
            status: 'error', 
            error: error.message 
        });
    }
});

// Root endpoint
app.get('/', (req, res) => {
    res.json({
        message: 'ðŸš€ WebMaster Pro Backend is LIVE!',
        version: '1.0.0',
        endpoints: ['/health', '/api/quick-chat', '/api/test/status']
    });
});

// Simple status check
app.get('/api/test/status', (req, res) => {
    res.json({
        server: 'running',
        ai_ready: !!(process.env.OPENAI_API_KEY || process.env.ANTHROPIC_API_KEY),
        timestamp: new Date().toISOString()
    });
});

// AI Chat endpoint with maximum error handling
app.post('/api/quick-chat', async (req, res) => {
    console.log('ðŸ’¬ Chat request received');
    
    try {
        const { message, model = 'fallback' } = req.body || {};
        
        if (!message) {
            return res.status(400).json({ 
                error: 'Message is required',
                received: req.body 
            });
        }

        let response = '';
        let usedModel = 'fallback';

        // Try OpenAI first
        if (process.env.OPENAI_API_KEY && (model === 'gpt' || model === 'auto')) {
            try {
                console.log('ðŸ¤– Trying OpenAI...');
                const { OpenAI } = require('openai');
                const openai = new OpenAI({ 
                    apiKey: process.env.OPENAI_API_KEY,
                    timeout: 10000 // 10 second timeout
                });
                
                const completion = await openai.chat.completions.create({
                    model: 'gpt-4',
                    messages: [
                        {
                            role: 'system',
                            content: 'You are a helpful AI assistant for WebMaster Pro. Respond in Hebrew when the user writes in Hebrew, in English when they write in English.'
                        },
                        {
                            role: 'user',
                            content: message
                        }
                    ],
                    max_tokens: 800,
                    temperature: 0.7
                });
                
                response = completion.choices[0].message.content;
                usedModel = 'gpt-4';
                console.log('âœ… OpenAI response generated');
                
            } catch (openaiError) {
                console.error('âŒ OpenAI failed:', openaiError.message);
                // Continue to Claude fallback
            }
        }

        // Try Claude if OpenAI failed or was requested
        if (!response && process.env.ANTHROPIC_API_KEY && (model === 'claude' || model === 'auto')) {
            try {
                console.log('ðŸ§  Trying Claude...');
                const Anthropic = require('@anthropic-ai/sdk');
                const anthropic = new Anthropic({ 
                    apiKey: process.env.ANTHROPIC_API_KEY,
                    timeout: 10000
                });
                
                const result = await anthropic.messages.create({
                    model: 'claude-3-sonnet-20240229',
                    max_tokens: 800,
                    system: 'You are a helpful AI assistant for WebMaster Pro. Respond in Hebrew when the user writes in Hebrew, in English when they write in English.',
                    messages: [{
                        role: 'user',
                        content: message
                    }]
                });
                
                response = result.content[0].text;
                usedModel = 'claude-3-sonnet';
                console.log('âœ… Claude response generated');
                
            } catch (claudeError) {
                console.error('âŒ Claude failed:', claudeError.message);
                // Continue to fallback
            }
        }

        // Fallback response if all AI fails
        if (!response) {
            response = `ðŸ¤– **WebMaster Pro Assistant**

×©×œ×•×! ×§×™×‘×œ×ª×™ ××ª ×”×”×•×“×¢×” ×©×œ×š: "${message}"

×›×¨×’×¢ ×× ×™ ×¢×•×‘×“ ×‘×ž×¦×‘ ×‘×˜×•×— ×¢× ×—×™×‘×•×¨ ×—×œ×§×™ ×œ-AI. 

**×ž×” ×©×× ×™ ×™×›×•×œ ×œ×¢×©×•×ª:**
âœ… ×”×©×¨×ª ×¤×•×¢×œ ×‘×”×¦×œ×—×”
âœ… ×ž×•×›×Ÿ ×œ×§×‘×œ ×‘×§×©×•×ª ×¢×¨×™×›×”
âœ… ×ž×¢×¨×›×ª Multi-AI ×ž×•×›× ×” ×˜×›× ×™×ª

**×œ×ž×” ×œ× ×§×™×‘×œ×ª ×ª×©×•×‘×ª AI ×ž×œ××”:**
â€¢ ×ž×¤×ª×—×•×ª API ×–×§×•×§×™× ×œ×‘×“×™×§×”
â€¢ ×™×ª×›×Ÿ ×©×™×© ×¢×•×ž×¡ ×–×ž× ×™
â€¢ ×”×¨×©×ª ××™×˜×™×ª

×× ××ª×” ×¨×•××” ××ª ×”×”×•×“×¢×” ×”×–×•, ×”×ž×¢×¨×›×ª ×¢×•×‘×“×ª! 
×‘×§×¨×•×‘ × ×—×‘×¨ ××ª ×”-AI ×‘×ž×œ×•××•.`;

            usedModel = 'fallback-system';
        }

        res.json({
            success: true,
            response,
            model: usedModel,
            timestamp: new Date().toISOString(),
            server_status: 'operational'
        });

    } catch (error) {
        console.error('âŒ Chat endpoint error:', error.message);
        res.status(500).json({ 
            success: false, 
            error: error.message,
            fallback_response: `âš ï¸ ×”×©×¨×ª ×¤×•×¢×œ ××‘×œ × ×ª×§×œ ×‘×‘×¢×™×” ×˜×›× ×™×ª ×–×ž× ×™×ª.\n\n×”×”×•×“×¢×” ×©×œ×š: "${req.body?.message || '×œ× ×”×ª×§×‘×œ×”'}"\n\n×”×ž×¢×¨×›×ª ×¤×¢×™×œ×” ×•×ª×ª×•×§×Ÿ ×‘×§×¨×•×‘.`
        });
    }
});

// Global error handler
app.use((error, req, res, next) => {
    console.error('ðŸš¨ Global error:', error.message);
    res.status(500).json({ 
        error: 'Server error', 
        message: error.message,
        timestamp: new Date().toISOString()
    });
});

// 404 handler
app.use((req, res) => {
    res.status(404).json({ 
        error: 'Endpoint not found',
        path: req.path,
        available_endpoints: ['/', '/health', '/api/quick-chat', '/api/test/status']
    });
});

// Start server with error handling
const startServer = () => {
    try {
        const server = app.listen(PORT, '0.0.0.0', () => {
            console.log('ðŸŽ‰ ====================================');
            console.log('ðŸš€ WebMaster Pro Backend STARTED!');
            console.log(`ðŸ“¡ Port: ${PORT}`);
            console.log(`ðŸŒ Environment: ${process.env.NODE_ENV || 'development'}`);
            console.log(`ðŸ¥ Health: http://localhost:${PORT}/health`);
            console.log(`ðŸ¤– AI Status:`);
            console.log(`   OpenAI: ${process.env.OPENAI_API_KEY ? 'âœ… Ready' : 'âŒ Missing'}`);
            console.log(`   Claude: ${process.env.ANTHROPIC_API_KEY ? 'âœ… Ready' : 'âŒ Missing'}`);
            console.log('ðŸŽ‰ ====================================');
        });

        server.on('error', (error) => {
            console.error('âŒ Server error:', error.message);
            if (error.code === 'EADDRINUSE') {
                console.log(`âš ï¸ Port ${PORT} is busy, trying ${PORT + 1}...`);
                PORT = PORT + 1;
                setTimeout(startServer, 1000);
            }
        });

        // Graceful shutdown
        process.on('SIGTERM', () => {
            console.log('ðŸ“´ Graceful shutdown...');
            server.close();
        });

    } catch (error) {
        console.error('ðŸ’¥ Failed to start server:', error.message);
        process.exit(1);
    }
};

// Initialize
console.log('ðŸ”§ Initializing WebMaster Pro...');
startServer();
